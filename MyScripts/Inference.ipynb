{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## imports ###\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.optimizer import Optimizer\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from models.lvae import LadderVAE\n",
    "from boilerplate import boilerplate\n",
    "import lib.utils as utils\n",
    "import training\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import zipfile\n",
    "import urllib\n",
    "from tifffile import imread, imsave\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "from MyScripts.crop_center import crop_center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "\n",
    "\n",
    "# Model \n",
    "modelName = \"Vim_mtlplSNR_Noise1_GMM1N2V_ConvTransposeBefore_Upsamp2_Clip-3_Lat64x5_6Blocks_betaKL0.0001_NoAugment\"\n",
    "modelPath = Path(\"./Trained_model/model/\") / (modelName + \"_best_vae.net\")\n",
    "\n",
    "# Data\n",
    "basedir = Path(r\"E:\\dl_monalisa\\Data\\Vim_fixed_mltplSNR_30nm\\_forAnirban\")\n",
    "data_path_signal = basedir / \"test_data\" / \"avg_and_n2v\"\n",
    "data_path_obs = basedir /  \"test_data\" / \"mltpl_snr_stacks\"\n",
    "\n",
    "# Normalization values\n",
    "mean_value = 32.78586959838867\n",
    "std_value = 70.50637817382812 \n",
    "\n",
    "# Data parameters\n",
    "upsamp = 2\n",
    "upsamp_beforeNN = False # put True to re-upsample with nearest neighbor before feeding in neural net\n",
    "DataNoiseLvl = [1,2] # \"all\", int, or list of int\n",
    "clip = -3\n",
    "\n",
    "if not upsamp_beforeNN:\n",
    "    crop_coeff = upsamp\n",
    "else:\n",
    "    crop_coeff = 1\n",
    "\n",
    "# Inference parameters\n",
    "crop_size = 200 # NOTE: crop size in \"output space\" after upsampling, so it should be a multiple of upsampling factor\n",
    "tiling = False # to predict whole image with tiling\n",
    "tilingMargin = 50 # tilingMargin added to crop_size to avoid edge effect when tiling\n",
    "\n",
    "num_samples = 10 # number of samples used to compute MMSE estimate\n",
    "tta = False\n",
    "\n",
    "# Saving prm\n",
    "saving = True\n",
    "save_suffix = \"\"\n",
    "save_folder = basedir / \"inference\" / (modelName + f\"_{save_suffix}\")\n",
    "overwrite = True\n",
    "\n",
    "save_samples = True\n",
    "save_mmse = True\n",
    "save_std = False\n",
    "save_var = False\n",
    "\n",
    "if saving:\n",
    "    if not os.path.exists(save_folder):\n",
    "        os.makedirs(save_folder)\n",
    "    else:\n",
    "        assert overwrite == True, \"Saving folder already exists. Set overwrite = True to enable overwriting inference folder\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "##### Load data ####\n",
    "\n",
    "signal = []\n",
    "observation = []\n",
    "filters = ['tif','tiff']\n",
    "\n",
    "files_signal = os.listdir(data_path_signal)\n",
    "files_obs = os.listdir(data_path_obs)\n",
    "\n",
    "for f in files_signal:\n",
    "    if f.split('.')[-1] not in filters:\n",
    "        print(f\"removing {f} in signals because not in filters\")\n",
    "        files_signal.remove(f)\n",
    "\n",
    "for f in files_obs:\n",
    "    if f.split('.')[-1] not in filters:\n",
    "        print(f\"Removing {f} in observations because not in filters\")\n",
    "        files_obs.remove(f)\n",
    "\n",
    "assert len(files_obs) == len(files_signal)\n",
    "n_images= len(files_obs)\n",
    "print(f\"\\nFound {n_images} images.\\n\")\n",
    "\n",
    "if isinstance(DataNoiseLvl,list) or DataNoiseLvl == \"all\":\n",
    "    mltplNoise = True\n",
    "else:\n",
    "    mltplNoise = False\n",
    "    nNoise = 1\n",
    "\n",
    "for i in range (len(files_obs)):\n",
    "    file_signal = files_signal [i]\n",
    "    file_obs = files_obs [i]\n",
    "    im_signal = imread(data_path_signal / file_signal)[0]\n",
    "    \n",
    "    # noise level selection\n",
    "    if DataNoiseLvl == \"all\":\n",
    "        im_obs  = imread(data_path_obs / file_obs)[:5]\n",
    "    elif isinstance(DataNoiseLvl,int) or isinstance(DataNoiseLvl,list):\n",
    "        try:\n",
    "            im_obs = imread(data_path_obs / file_obs)[DataNoiseLvl]\n",
    "        except IndexError:\n",
    "            continue\n",
    "\n",
    "    if not isinstance(clip,bool):\n",
    "        im_obs[im_obs<clip] = 0\n",
    "        im_signal[im_signal<clip] = 0\n",
    "\n",
    "\n",
    "    observation.append(im_obs)\n",
    "    signal.append(im_signal)\n",
    "\n",
    "    print(f\"Signal {file_signal}:\\tObservation {file_obs}:\\t Shape: {im_obs.shape}\")\n",
    "\n",
    "# Stack to numpy array\n",
    "signal = np.stack(signal)\n",
    "observation = np.stack(observation)\n",
    "\n",
    "# Adjust array dimension if necessary\n",
    "if mltplNoise:\n",
    "    nNoise = observation.shape[1]\n",
    "    nrepeat = observation.shape[1]\n",
    "    observation = np.reshape(observation,(observation.shape[0]*observation.shape[1],observation.shape[2],observation.shape[3]))    \n",
    "    signal = np.repeat(signal,nrepeat,axis=0)\n",
    "\n",
    "# square crop (like in training)\n",
    "if signal.shape[-1] != signal.shape[-2]:\n",
    "    print(\"Cropping to square\")\n",
    "    img_size = min(signal.shape[-1],signal.shape[-2])\n",
    "    signal = crop_center(signal,img_size)\n",
    "    observation = crop_center(observation,img_size)\n",
    "\n",
    "#if tiling, we crop so that img size is a multiple of crop_size\n",
    "if tiling and img_size%crop_size!=0:\n",
    "    img_size = img_size - img_size%crop_size\n",
    "    signal = crop_center(signal,img_size)\n",
    "    observation = crop_center(observation,img_size)\n",
    "\n",
    "# Normalization\n",
    "signal = (signal - (mean_value))/(std_value) \n",
    "observation = (observation - (mean_value))/(std_value)\n",
    "\n",
    "# downsampling input\n",
    "if upsamp>1:\n",
    "    observation2 = []\n",
    "    for im in observation:\n",
    "        dwnsamp=im[::upsamp,::upsamp]\n",
    "        if upsamp_beforeNN:\n",
    "            interp=cv2.resize(dwnsamp, None, fx=upsamp, fy=upsamp, interpolation= cv2.INTER_CUBIC)\n",
    "            observation2.append(interp)\n",
    "        else:\n",
    "            observation2.append(dwnsamp)\n",
    "    observation = np.stack(observation2)\n",
    "\n",
    "print(f\"\\n\\nConcatenated arrays and cropped:\\tSignal: {signal.shape}\\tObservation: {observation.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display examples\n",
    "\n",
    "idxs = np.random.randint(0,observation.shape[0],2)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(1,4,1)\n",
    "plt.imshow(crop_center(observation[idxs[0]],crop_size//crop_coeff),cmap=\"gray\")\n",
    "plt.title(\"Noisy\")\n",
    "\n",
    "plt.subplot(1,4,2)\n",
    "plt.imshow(crop_center(signal[idxs[0]],crop_size),cmap=\"gray\")\n",
    "plt.title(\"Clean\")\n",
    "\n",
    "plt.subplot(1,4,3)\n",
    "plt.imshow(crop_center(observation[idxs[1]],crop_size//crop_coeff),cmap=\"gray\")\n",
    "plt.title(\"Noisy\")\n",
    "\n",
    "plt.subplot(1,4,4)\n",
    "plt.imshow(crop_center(signal[idxs[1]],crop_size),cmap=\"gray\")\n",
    "plt.title(\"Clean\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference \n",
    "\n",
    "model = torch.load(modelPath)\n",
    "model.mode_pred=True\n",
    "model.eval()\n",
    "\n",
    "gaussian_noise_std = None\n",
    "img_mmse_list = []\n",
    "samples_list = []\n",
    "tiling = False\n",
    "# simple inference\n",
    "if not tiling:\n",
    "    signal = crop_center(signal,crop_size)\n",
    "    observation = crop_center(observation,crop_size//crop_coeff)\n",
    "    for i in range (n_images):\n",
    "        for noise in range (nNoise):\n",
    "            input = observation[i*nNoise+noise]\n",
    "            img_mmse, samples = boilerplate.predict(input,num_samples,model,gaussian_noise_std,device,tta)\n",
    "            img_mmse_list.append(img_mmse)\n",
    "            samples_list.append(np.stack(samples))\n",
    "\n",
    "\n",
    "# inference of full image with tiling\n",
    "else:\n",
    "    tilingMargin_inp = tilingMargin//crop_coeff\n",
    "    crop_size_inp = crop_size//crop_coeff\n",
    "    for i in range (n_images):\n",
    "        for noise in range (nNoise):\n",
    "            obs = np.pad(observation[i*nNoise+noise],(tilingMargin_inp,tilingMargin_inp))\n",
    "            img_mmse = np.zeros([img_size,img_size],dtype='float32')\n",
    "            samples = np.zeros([num_samples,img_size,img_size])\n",
    "            for y in range(tilingMargin,img_size-tilingMargin,crop_size):\n",
    "                for x in range(tilingMargin,img_size-tilingMargin,crop_size):\n",
    "                    x1 = x//crop_coeff-tilingMargin_inp\n",
    "                    y1 = y//crop_coeff-tilingMargin_inp\n",
    "                    x2 = x//crop_coeff + crop_size_inp + tilingMargin_inp\n",
    "                    y2 = y//crop_coeff + crop_size_inp + tilingMargin_inp\n",
    "                    # img_mmse_crop, samples_crop = boilerplate.predict(obs[y:y+crop_size_inp,x:x+crop_size_inp],num_samples,model,gaussian_noise_std,device,tta)\n",
    "                    img_mmse_crop, samples_crop = boilerplate.predict(obs[y1:y2,x1:x2],num_samples,model,gaussian_noise_std,device,tta)\n",
    "\n",
    "                    img_mmse[y-tilingMargin:y+crop_size-tilingMargin,x-tilingMargin:x+crop_size-tilingMargin] = img_mmse_crop[tilingMargin:-tilingMargin,tilingMargin:-tilingMargin]\n",
    "                    samples[:,y-tilingMargin:y+crop_size-tilingMargin,x-tilingMargin:x+crop_size-tilingMargin] = np.stack(samples_crop,axis=0)[:,tilingMargin:-tilingMargin,tilingMargin:-tilingMargin]\n",
    "\n",
    "\n",
    "            img_mmse_list.append(img_mmse)\n",
    "            samples_list.append(np.stack(samples))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display\n",
    "\n",
    "idx=0\n",
    "colormap = \"gray\"\n",
    "\n",
    "plt.figure(figsize=(18,6))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(signal[idx],cmap = colormap)\n",
    "plt.title(\"GT\")\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(observation[idx],cmap = colormap)\n",
    "plt.title(\"Input\")\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(img_mmse_list[idx],cmap = colormap)\n",
    "plt.title(\"Pred\")\n",
    "\n",
    "# also show smaller region crop if tiling\n",
    "if tiling:\n",
    "    plt.figure(figsize=(18,6))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(crop_center(signal[idx],crop_size),cmap = colormap)\n",
    "    plt.title(\"GT\")\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow(crop_center(observation[idx],crop_size//crop_coeff),cmap = colormap)\n",
    "    plt.title(\"Input\")\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.imshow(crop_center(img_mmse_list[idx],crop_size),cmap = colormap)\n",
    "    plt.title(\"Pred\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Saving:\n",
    "#   - if single noise level, results are saved as a stack: gt-inp-mmse (and samples in a different file)\n",
    "#   - if mltpl noise level, results of all noise are saved as a single stack: gt first, then [inp-mmse] pair for each noise level (samples saved separetly for each noise level)\n",
    "#   - NOTE: if input not upsampled before net, it is upsample with nearest neighbor to match gt and pred size\n",
    "\n",
    "\n",
    "# single noise level\n",
    "if saving and not mltplNoise:\n",
    "    for i in range(observation.shape[0]):\n",
    "        if not upsamp_beforeNN:\n",
    "            input = cv2.resize(observation[i],None,fx=upsamp, fy=upsamp, interpolation= cv2.INTER_NEAREST)\n",
    "        else:\n",
    "            input = observation[i]\n",
    "        summary = np.stack([signal[i],input,img_mmse_list[i]],axis=0)\n",
    "        samples = samples_list[i]\n",
    "        std = np.std(samples,axis=0)\n",
    "        var = np.var(samples,axis=0)\n",
    "        if save_mmse:\n",
    "            imsave(save_folder / f\"gt_inp_mmse{num_samples}_Noise{DataNoiseLvl}_{i:02d}.tif\",summary,imagej=True,metadata={'axes':'TYX'})\n",
    "        if save_samples:\n",
    "            imsave(save_folder / f\"samples_{i:02d}_Noise{DataNoiseLvl}_.tif\",samples)\n",
    "        if save_std:\n",
    "            imsave(save_folder / f\"std_{i:02d}_Noise{DataNoiseLvl}_.tif\",std)\n",
    "        if save_var:\n",
    "            imsave(save_folder / f\"var_{i:02d}_Noise{DataNoiseLvl}_.tif\",var)   \n",
    "\n",
    "\n",
    "# multiple noise level\n",
    "elif saving and mltplNoise:\n",
    "    for i in range(n_images):\n",
    "        summary = [signal[i*nNoise]] \n",
    "        for noise in range(nNoise):\n",
    "            if not upsamp_beforeNN:\n",
    "                input = cv2.resize(observation[i*nNoise+noise],None,fx=upsamp, fy=upsamp, interpolation= cv2.INTER_NEAREST)\n",
    "            else:\n",
    "                input = observation[i*nNoise+noise]\n",
    "            summary.append(input)\n",
    "            summary.append(img_mmse_list[i*nNoise+noise])\n",
    "            samples = samples_list[i*nNoise+noise] \n",
    "            std = np.std(samples,axis=0)\n",
    "            std_norm = std / img_mmse_list[i*nNoise+noise]\n",
    "            var = np.var(samples,axis=0)\n",
    "            var_norm = var / img_mmse_list[i*nNoise+noise]\n",
    "            if save_samples:\n",
    "                imsave(save_folder / f\"samples_{i:02d}_Noise{noise}_{i:02d}.tif\",samples)\n",
    "            if save_std:\n",
    "                imsave(save_folder / f\"std_{i:02d}_Noise{noise}_{i:02d}.tif\",std)\n",
    "                imsave(save_folder / f\"std_norm{i:02d}_Noise{noise}_{i:02d}.tif\",std_norm)\n",
    "            if save_var:\n",
    "                imsave(save_folder / f\"var_{i:02d}_Noise{noise}_{i:02d}.tif\",var)\n",
    "                imsave(save_folder / f\"var_norm{i:02d}_Noise{noise}_{i:02d}.tif\",var_norm)\n",
    "        \n",
    "        summary=np.stack(summary,axis=0)\n",
    "\n",
    "        if save_mmse:\n",
    "            if isinstance(DataNoiseLvl,list):\n",
    "                noise_level_str = ''.join(str(DataNoiseLvl).split(', '))[1:-1]\n",
    "            else:\n",
    "                noise_level_str = DataNoiseLvl\n",
    "            imsave(save_folder / f\"gt_inp_mmse{num_samples}_Noise{noise_level_str}_{i:02d}.tif\",summary,imagej=True,metadata={'axes':'TYX'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_monalisa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
