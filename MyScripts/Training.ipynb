{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# We import all our dependencies.\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from models.lvae import LadderVAE\n",
    "from lib.gaussianMixtureNoiseModel import GaussianMixtureNoiseModel\n",
    "from boilerplate import boilerplate\n",
    "import lib.utils as utils\n",
    "import training\n",
    "from tifffile import imread\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from pystackreg import StackReg\n",
    "from skimage.transform import warp,AffineTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(\"Device: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### ALL PARAMETERS DEFINED HERE ####\n",
    "\n",
    "supervised = False\n",
    "augment = True\n",
    "\n",
    "# Data paths\n",
    "data_path_signal = Path(r\"E:\\dl_monalisa\\Data\\Vim_fixed_mltplSNR_30nm\\inference\\N2V\\Vim_fixed_Avg1-3_no_clipping\")\n",
    "data_path_obs = Path(r\"E:\\dl_monalisa\\Data\\Vim_fixed_mltplSNR_30nm\\dump\\rec\\timelapses_gathered\")\n",
    "noiseModelsDir = Path(r\"E:\\dl_monalisa\\Data\\Vim_fixed_mltplSNR_30nm\\noise_models\\final_Reg\")\n",
    "\n",
    "# Choose parameters\n",
    "DataNoiseLvl = 0 # \"all\",list of int, or int\n",
    "GMMNoiseLvl = \"same\"\n",
    "clean = \"n2v\" # \"n2v\" or \"avg\"\n",
    "display = True # display images or not\n",
    "clip = -3 # False or clip value\n",
    "registration = True\n",
    "\n",
    "# Get noise model name\n",
    "if GMMNoiseLvl == \"same\":\n",
    "    GMMNoiseLvl = DataNoiseLvl\n",
    "GMMname = f\"GMM_Noise{GMMNoiseLvl}_Sig{clean.upper()}_Clip{clip}.npz\"\n",
    "assert os.path.exists(noiseModelsDir/GMMname)\n",
    "\n",
    "print(f\"Supervised: {supervised}\")\n",
    "print(f\"Noise level: {DataNoiseLvl}\")\n",
    "print(f\"GMM noise level: {GMMNoiseLvl}\")\n",
    "print(f\"Clean: {clean}\")\n",
    "print(f\"GMM: {GMMname}\")\n",
    "\n",
    "# Training prm\n",
    "patch_size = 64\n",
    "gaussian_noise_std = None\n",
    "\n",
    "# Training-specific\n",
    "beta = 0.45 # loss = recon_loss + beta * kl_loss\n",
    "batch_size=64\n",
    "virtual_batch = 8\n",
    "lr=1e-4\n",
    "max_epochs = 500\n",
    "steps_per_epoch=400\n",
    "test_batch_size=10\n",
    "\n",
    "# Model-specific\n",
    "num_latents = 5\n",
    "z_dims = [32]*int(num_latents)\n",
    "blocks_per_layer = 6\n",
    "batchnorm = True\n",
    "free_bits = 1.0\n",
    "\n",
    "# Model name for saving\n",
    "data_name = str(data_path_signal).split(\"\\\\\")[3]\n",
    "modelName = f\"{data_name}_Noise{DataNoiseLvl}GMM{GMMNoiseLvl}_Sig{clean.upper()}_Clip{clip}_{num_latents}Lat_{blocks_per_layer}Blocks_betaKL{beta}\"\n",
    "if supervised:\n",
    "    modelName = modelName + \"_Supervised\"\n",
    "if not augment:\n",
    "    modelName = modelName + \"_NoAugment\"\n",
    "\n",
    "save_model_basedir = \"./Trained_model/\" \n",
    "print(f\"Trained model will be saved at: {save_model_basedir}\")\n",
    "print(f\"Model save name: {modelName}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### Load data ####\n",
    "\n",
    "signal = []\n",
    "observation = []\n",
    "filters = ['tif','tiff']\n",
    "\n",
    "files_signal = os.listdir(data_path_signal)\n",
    "files_obs = os.listdir(data_path_obs)\n",
    "\n",
    "for f in files_signal:\n",
    "    if f.split('.')[-1] not in filters:\n",
    "        print(f\"removing {f} in signals because not in filters\")\n",
    "        files_signal.remove(f)\n",
    "\n",
    "for f in files_obs:\n",
    "    if f.split('.')[-1] not in filters:\n",
    "        print(f\"Removing {f} in observations because not in filters\")\n",
    "        files_obs.remove(f)\n",
    "\n",
    "assert len(files_obs) == len(files_signal)\n",
    "print(f\"\\nFound {len(files_signal)} files.\\n\")\n",
    "\n",
    "for i in range (len(files_obs)):\n",
    "    file_signal = files_signal [i]\n",
    "    file_obs = files_obs [i]\n",
    "    \n",
    "    # n2v or avg signal selection\n",
    "    if clean == \"avg\":\n",
    "        im_signal = imread(data_path_signal / file_signal)[0]\n",
    "    elif clean == \"n2v\":\n",
    "        im_signal = imread(data_path_signal / file_signal)[1]\n",
    "    \n",
    "    # noise level selection\n",
    "    if DataNoiseLvl == \"all\":\n",
    "        im_obs  = imread(data_path_obs / file_obs)[:5]\n",
    "    elif isinstance(DataNoiseLvl,int) or isinstance(DataNoiseLvl,list):\n",
    "        im_obs = imread(data_path_obs / file_obs)[DataNoiseLvl]\n",
    "\n",
    "    if not isinstance(clip,bool):\n",
    "        im_obs[im_obs<clip] = 0\n",
    "        im_signal[im_signal<clip] = 0\n",
    "\n",
    "    if registration:\n",
    "        if DataNoiseLvl == \"all\":\n",
    "            print(\"Registration not available for all noise level yet\")\n",
    "        else:\n",
    "            tf = StackReg.TRANSLATION\n",
    "            sr = StackReg(tf)\n",
    "            tmat = sr.register(ref=im_signal,mov=im_obs)\n",
    "            tform = AffineTransform(matrix=tmat)\n",
    "            im_obs = warp(im_obs, tform,order=0)\n",
    "\n",
    "    observation.append(im_obs)\n",
    "    signal.append(im_signal)\n",
    "\n",
    "    print(f\"Signal {file_signal}:\\tObservation {file_obs}:\\t Shape: {im_obs.shape}\")\n",
    "\n",
    "signal = np.stack(signal)\n",
    "observation = np.stack(observation)\n",
    "\n",
    "if len(observation.shape) == 4:\n",
    "    nrepeat = observation.shape[1]\n",
    "    observation = np.reshape(observation,(observation.shape[0]*observation.shape[1],observation.shape[2],observation.shape[3]))    \n",
    "    signal = np.repeat(signal,nrepeat,axis=0)\n",
    "\n",
    "\n",
    "if signal.shape[-1] != signal.shape[-2]:\n",
    "    print(\"Cropping to square\")\n",
    "    a = min(signal.shape[-1],signal.shape[-2])\n",
    "    signal = signal [...,0:a,0:a]\n",
    "    observation = observation [...,0:a,0:a]\n",
    "\n",
    "print(f\"Mean signal {np.mean(signal)}, std signal {np.std(signal)} \")\n",
    "print(f\"Mean observation {np.mean(observation)}, std observation {np.std(observation)} \")\n",
    "signal = (signal - np.mean(signal))/np.std(signal)\n",
    "observation = (observation - np.mean(observation))/np.std(observation)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\n\\nConcatenated arrays:\\tSignal: {signal.shape}\\tObservation: {observation.shape}\")\n",
    "\n",
    "plt.figure(figsize=(10,20))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(observation[0][400:800,400:800])\n",
    "plt.title(\"Noisy\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(signal[0][400:800,400:800])\n",
    "plt.title(\"Clean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split into train and val, define gt data if supervised\n",
    "\n",
    "train_data = observation[:int(0.85*observation.shape[0])]\n",
    "val_data= observation[int(0.85*observation.shape[0]):]\n",
    "print(\"Shape of training images:\", train_data.shape, \"Shape of validation images:\", val_data.shape)\n",
    "if augment:\n",
    "    train_data = utils.augment_data(train_data) ### Data augmentation disabled for fast training, but can be enabled\n",
    "### Optional part with GT data if supervised###\n",
    "if supervised:\n",
    "    train_data_gt = signal[:int(0.85*observation.shape[0])]\n",
    "    val_data_gt = signal[int(0.85*observation.shape[0]):]\n",
    "    print(\"Shape of GT training images:\", train_data.shape, \"Shape of validation images:\", val_data.shape)\n",
    "    if augment:\n",
    "        train_data_gt = utils.augment_data(train_data_gt) ### Data augmentation disabled for fast training, but can be enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Patches extraction\n",
    "\n",
    "img_width = observation.shape[2]\n",
    "img_height = observation.shape[1]\n",
    "num_patches = int(float(img_width*img_height)/float(patch_size**2)*1)\n",
    "\n",
    "if not supervised:\n",
    "    train_images = utils.extract_patches(train_data, patch_size, num_patches)\n",
    "    val_images = utils.extract_patches(val_data, patch_size, num_patches)\n",
    "else:\n",
    "    train_images,train_images_gt = utils.extract_patches_supervised(train_data,train_data_gt, patch_size, num_patches)\n",
    "    val_images,val_images_gt  = utils.extract_patches_supervised(val_data,val_data_gt, patch_size, num_patches)\n",
    "\n",
    " # We limit validation patches to 1000 to speed up training but it is not necessary\n",
    "val_images = val_images[:1000]\n",
    "test_images = val_images[:100]\n",
    "if supervised:\n",
    "    val_images_gt = val_images_gt [:1000] \n",
    "    test_images_gt = val_images_gt[:100]\n",
    "    \n",
    "img_shape = (train_images.shape[1], train_images.shape[2])\n",
    "print(\"Shape of training images:\", train_images.shape, \"Shape of validation images:\", val_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if supervised: Display of paired dataset to check that it is matching \n",
    "\n",
    "if supervised:\n",
    "    import random\n",
    "    idx = random.randrange(train_images.shape[0])\n",
    "\n",
    "    plt.figure(figsize=(5,10))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(train_images[idx])\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(train_images_gt[idx])\n",
    "\n",
    "    idx = random.randrange(val_images.shape[0])\n",
    "    plt.figure(figsize=(5,10))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(val_images[idx])\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(val_images_gt[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Choose make_data_manager for supervised training or make_data_manager 2 for supervised\n",
    "\n",
    "if not supervised:\n",
    "    train_loader, val_loader, test_loader, data_mean, data_std = boilerplate._make_datamanager(train_images,val_images,\n",
    "                                                                                            test_images,batch_size,\n",
    "                                                                                            test_batch_size)\n",
    "\n",
    "else:\n",
    "    train_loader, val_loader, test_loader, data_mean, data_std = boilerplate._make_datamanager_supervised(train_images,train_images_gt,val_images,\n",
    "                                                                                            val_images_gt, test_images,test_images_gt,\n",
    "                                                                                            batch_size,test_batch_size)\n",
    "\n",
    "# Here we ensure that steps_per_epoch not bigger than len(train_loader)\n",
    "# It never goes into validation otherwise, and so it never saves the model.\n",
    "steps_per_epoch=min(len(train_loader)-1,steps_per_epoch)\n",
    "print(steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_mean,data_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if supervised: Display of paired dataset to check that it is still matching in the loader  \n",
    "\n",
    "if supervised:\n",
    "    batch_idx, (x, y) = next(enumerate(train_loader))\n",
    "\n",
    "    x2 = x.cpu().numpy()\n",
    "    x2 = x2[0]\n",
    "\n",
    "    y2 = y.cpu().numpy()\n",
    "    y2 = y2[0]\n",
    "\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(x2)\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(y2)\n",
    "\n",
    "    batch_idx, (x, y) = next(enumerate(val_loader))\n",
    "\n",
    "    x2 = x.cpu().numpy()\n",
    "    x2 = x2[0]\n",
    "\n",
    "    y2 = y.cpu().numpy()\n",
    "    y2 = y2[0]\n",
    "\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(x2)\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train network\n",
    "\n",
    "noise_model_params= np.load(str(noiseModelsDir / GMMname))\n",
    "noiseModel = GaussianMixtureNoiseModel(params = noise_model_params, device = device)\n",
    "\n",
    "model = LadderVAE(z_dims=z_dims,blocks_per_layer=blocks_per_layer,data_mean=data_mean,data_std=data_std,noiseModel=noiseModel,\n",
    "                  device=device,batchnorm=batchnorm,free_bits=free_bits,img_shape=img_shape).cuda()\n",
    "\n",
    "model.train() # Model set in training mode\n",
    "\n",
    "training.train_network(model=model,lr=lr,max_epochs=max_epochs,steps_per_epoch=steps_per_epoch,directory_path=save_model_basedir,\n",
    "                       train_loader=train_loader,val_loader=val_loader,test_loader=test_loader,\n",
    "                       virtual_batch=virtual_batch,gaussian_noise_std=gaussian_noise_std,\n",
    "                       model_name=modelName,val_loss_patience=100,beta=beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "directory_path = \"./Trained_model/\" \n",
    "trainHist=np.load(directory_path+\"model/train_loss.npy\")\n",
    "reconHist=np.load(directory_path+\"model/train_reco_loss.npy\")\n",
    "klHist=np.load(directory_path+\"model/train_kl_loss.npy\")\n",
    "valHist=np.load(directory_path+\"model/val_loss.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 3))\n",
    "plt.subplot(1,3,1)\n",
    "plt.plot(trainHist,label='training')\n",
    "plt.plot(valHist,label='validation')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(reconHist,label='training')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"reconstruction loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.plot(klHist,label='training')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"KL loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_monalisa_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
