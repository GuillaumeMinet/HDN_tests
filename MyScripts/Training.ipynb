{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## imports ###\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from models.lvae import LadderVAE\n",
    "from lib.gaussianMixtureNoiseModel import GaussianMixtureNoiseModel\n",
    "from boilerplate import boilerplate\n",
    "import lib.utils as utils\n",
    "from lib import histNoiseModel\n",
    "from lib.utils import plotProbabilityDistribution\n",
    "import training\n",
    "from tifffile import imread\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from pathlib import Path\n",
    "from skimage.transform import warp,AffineTransform\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(\"Device: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### ALL PARAMETERS DEFINED HERE ####\n",
    "\n",
    "display = True\n",
    "\n",
    "# Data paths\n",
    "basedir = Path(r\"E:\\dl_monalisa\\Data\\Vim_fixed_mltplSNR_30nm\\_forAnirban\")\n",
    "data_path_signal = basedir / \"training_data\" / \"avg_and_n2v\"\n",
    "data_path_obs = basedir /  \"training_data\" / \"mltpl_snr_stacks\"\n",
    "\n",
    "# Noise Model\n",
    "noiseModelsDir = basedir / \"noiseModel\"\n",
    "GMMname = \"GMM_Noise1_SigN2V_Clip-3.npz\"\n",
    "noise_model_params = np.load(str(noiseModelsDir / GMMname))\n",
    "noiseModel = GaussianMixtureNoiseModel(params = noise_model_params, device = device)\n",
    "\n",
    "# Data-related parameters\n",
    "\n",
    "upsamp = 2 # upsampling factor (integer) NOTE: for now only upsamp by 2 possible in HDN\n",
    "\n",
    "upsamp_beforeNN = False # if True, input upsampled w/ nearest neighbor before feeding into network. \n",
    "                        # if False, upsampled done in network.\n",
    "\n",
    "target = \"clean\" # \"noisy\" or \"clean\"\n",
    "augment = False\n",
    "DataNoiseLvl = 1 # \"all\",list of int, or int \n",
    "normSignalToObs = True # put True if signal was normalized to observations when creating GMM\n",
    "normGMM = True # put True if data was normalized to create the GMM\n",
    "clip = -3 # False or clip value\n",
    "\n",
    "# Model-specific\n",
    "num_latents = 5\n",
    "z_dim = 64\n",
    "z_dims = [z_dim]*int(num_latents)\n",
    "blocks_per_layer = 6\n",
    "batchnorm = True\n",
    "free_bits = 0\n",
    "n_filters = 128\n",
    "\n",
    "# Training prm\n",
    "patch_size = 64\n",
    "gaussian_noise_std = None\n",
    "beta = 0.0001 # loss = recon_loss + beta * kl_loss\n",
    "batch_size=64\n",
    "virtual_batch = 8\n",
    "lr=1e-5\n",
    "max_epochs = 500\n",
    "steps_per_epoch=400\n",
    "test_batch_size=10\n",
    "\n",
    "# Model name for saving\n",
    "model_name_base = \"Vim_mtlplSNR_Noise1_GMM1N2V_ConvTransposeBefore\"\n",
    "modelName = f\"{model_name_base}_Upsamp{upsamp}_Clip{clip}_Lat{z_dim}x{num_latents}_{blocks_per_layer}Blocks_betaKL{beta}\"\n",
    "if not augment:\n",
    "    modelName = modelName + \"_NoAugment\"\n",
    "\n",
    "save_model_basedir = \"./Trained_model/\" \n",
    "\n",
    "print(f\"Upsamp factor: {upsamp}\")\n",
    "print(f\"Target: {target}\")\n",
    "print(f\"Noise level: {DataNoiseLvl}\")\n",
    "print(f\"GMM: {GMMname}\")\n",
    "\n",
    "print(f\"Trained model will be saved at: {save_model_basedir}\")\n",
    "print(f\"Model save name: {modelName}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### Load data ####\n",
    "signal = []\n",
    "observation = []\n",
    "filters = ['tif','tiff']\n",
    "\n",
    "files_signal = os.listdir(data_path_signal)\n",
    "files_obs = os.listdir(data_path_obs)\n",
    "\n",
    "for f in files_signal:\n",
    "    if f.split('.')[-1] not in filters:\n",
    "        print(f\"removing {f} in signals because not in filters\")\n",
    "        files_signal.remove(f)\n",
    "\n",
    "for f in files_obs:\n",
    "    if f.split('.')[-1] not in filters:\n",
    "        print(f\"Removing {f} in observations because not in filters\")\n",
    "        files_obs.remove(f)\n",
    "\n",
    "assert len(files_obs) == len(files_signal)\n",
    "print(f\"\\nFound {len(files_signal)} files.\\n\")\n",
    "\n",
    "if isinstance(DataNoiseLvl,list) or DataNoiseLvl == \"all\":\n",
    "    mltplNoise = True\n",
    "else:\n",
    "    mltplNoise = False\n",
    "\n",
    "for i in range (len(files_obs)):\n",
    "    file_signal = files_signal [i]\n",
    "    file_obs = files_obs [i]\n",
    "    \n",
    "    # load clean\n",
    "    im_signal = imread(data_path_signal / file_signal)[0]\n",
    "    \n",
    "    # load noisy\n",
    "    if DataNoiseLvl == \"all\":\n",
    "        im_obs  = imread(data_path_obs / file_obs)[:5]\n",
    "    elif isinstance(DataNoiseLvl,int) or isinstance(DataNoiseLvl,list):\n",
    "        im_obs = imread(data_path_obs / file_obs)[DataNoiseLvl]\n",
    "\n",
    "    # clip neg values\n",
    "    if not isinstance(clip,bool):\n",
    "        im_obs[im_obs<clip] = 0\n",
    "        im_signal[im_signal<clip] = 0\n",
    "\n",
    "    observation.append(im_obs)\n",
    "    signal.append(im_signal)\n",
    "\n",
    "    print(f\"Signal {file_signal}:\\tObservation {file_obs}:\\t Shape: {im_obs.shape}\")\n",
    "\n",
    "signal = np.stack(signal)\n",
    "observation = np.stack(observation)\n",
    "\n",
    "if mltplNoise:\n",
    "    nNoise = observation.shape[1]\n",
    "    nrepeat = observation.shape[1]\n",
    "    observation = np.reshape(observation,(observation.shape[0]*observation.shape[1],observation.shape[2],observation.shape[3]))    \n",
    "    signal = np.repeat(signal,nrepeat,axis=0)\n",
    "\n",
    "# square crop\n",
    "if signal.shape[-1] != signal.shape[-2]:\n",
    "    print(\"Cropping to square\")\n",
    "    a = min(signal.shape[-1],signal.shape[-2])\n",
    "    signal = signal [...,0:a,0:a]\n",
    "    observation = observation [...,0:a,0:a]\n",
    "\n",
    "# opt. normalization signal to target \n",
    "if normSignalToObs:\n",
    "    if mltplNoise:\n",
    "        signal = (signal - np.mean(signal))/np.std(signal)\n",
    "        for noise in range(nNoise):\n",
    "            signal[noise::nNoise] = signal[noise::nNoise] * np.std(observation[noise::nNoise]) + np.mean(observation[noise::nNoise])\n",
    "    else:\n",
    "        signal = (signal - np.mean(signal))/np.std(signal)\n",
    "        signal = signal * np.std(observation) + np.mean(observation)\n",
    "\n",
    "\n",
    "print(\"Before normalization:\")\n",
    "print(f\"Mean signal {np.mean(signal)}, std signal {np.std(signal)} \")\n",
    "print(f\"Mean observation {np.mean(observation)}, std observation {np.std(observation)} \")\n",
    "\n",
    "# opt. normalization of data\n",
    "if normGMM:\n",
    "    signal = (signal - np.mean(observation)) / np.std(observation)\n",
    "    observation = (observation - np.mean(observation)) / np.std(observation)\n",
    "\n",
    "    print(\"After normalization:\")\n",
    "    print(f\"Mean signal {np.mean(signal)}, std signal {np.std(signal)} \")\n",
    "    print(f\"Mean observation {np.mean(observation)}, std observation {np.std(observation)} \")\n",
    "\n",
    "print(f\"\\n\\nConcatenated arrays:\\tSignal: {signal.shape}\\tObservation: {observation.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display examples\n",
    "plt.figure(figsize=(10,20))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(observation[0][100:500,800:1200],cmap='gray')\n",
    "plt.title(\"Noisy\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(signal[0][100:500,800:1200],cmap='gray')\n",
    "plt.title(\"Clean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Train/val split and patch extraction ###\n",
    "\n",
    "train_data = observation[:int(0.85*observation.shape[0])]\n",
    "val_data= observation[int(0.85*observation.shape[0]):]\n",
    "print(\"Shape of training images:\", train_data.shape, \"Shape of validation images:\", val_data.shape)\n",
    "if augment:\n",
    "    train_data = utils.augment_data(train_data) ### Data augmentation disabled for fast training, but can be enabled\n",
    "\n",
    "\n",
    "if target == \"clean\":\n",
    "    train_data_gt = signal[:int(0.85*observation.shape[0])]\n",
    "    val_data_gt = signal[int(0.85*observation.shape[0]):]\n",
    "    print(\"Shape of GT training images:\", train_data.shape, \"Shape of validation images:\", val_data.shape)\n",
    "    if augment:\n",
    "        train_data_gt = utils.augment_data(train_data_gt) ### Data augmentation disabled for fast training, but can be enabled\n",
    "\n",
    "\n",
    "# Patches extraction\n",
    "img_width = observation.shape[2]\n",
    "img_height = observation.shape[1]\n",
    "num_patches = int(float(img_width*img_height)/float(patch_size**2)*1)\n",
    "\n",
    "if target == \"noisy\":\n",
    "    train_images = utils.extract_patches(train_data, patch_size, num_patches)\n",
    "    val_images = utils.extract_patches(val_data, patch_size, num_patches)\n",
    "\n",
    "elif target == \"clean\":\n",
    "    train_images,train_images_gt = utils.extract_patches_supervised(train_data,train_data_gt, patch_size, num_patches)\n",
    "    val_images,val_images_gt  = utils.extract_patches_supervised(val_data,val_data_gt, patch_size, num_patches)\n",
    "\n",
    "# We limit validation patches to 1000 to speed up training but it is not necessary\n",
    "val_images = val_images[:1000]\n",
    "if target == \"clean\":\n",
    "    val_images_gt = val_images_gt [:1000] \n",
    "\n",
    "\n",
    "img_shape = (train_images.shape[1], train_images.shape[2])\n",
    "\n",
    "# Display of paired dataset to check that it is matching \n",
    "if target == \"clean\":\n",
    "    import random\n",
    "    idx = random.randrange(train_images.shape[0])\n",
    "\n",
    "    plt.figure(figsize=(5,10))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(train_images[idx])\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(train_images_gt[idx])\n",
    "\n",
    "    idx = random.randrange(val_images.shape[0])\n",
    "    plt.figure(figsize=(5,10))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(val_images[idx])\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(val_images_gt[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Dataloaders ###\n",
    "\n",
    "if target == \"noisy\":\n",
    "    train_images_gt = train_images.copy()\n",
    "    val_images_gt = val_images.copy()\n",
    "\n",
    "train_loader, val_loader, data_mean, data_std = boilerplate._make_datamanager_supervised(train_images,train_images_gt,val_images,\n",
    "                                                                                            val_images_gt,batch_size,test_batch_size,\n",
    "                                                                                            upsamp=upsamp,upsamp_beforeNN = upsamp_beforeNN)\n",
    "\n",
    "\n",
    "# To make sure that steps_per_epoch not bigger than len(train_loader)\n",
    "steps_per_epoch=min(len(train_loader)-1,steps_per_epoch)\n",
    "# print(steps_per_epoch)\n",
    "\n",
    "# Display 1 patch example for each train and val loader\n",
    "batch_idx, (x, y) = next(enumerate(train_loader))\n",
    "\n",
    "idx=0\n",
    "x2 = x.cpu().numpy()\n",
    "x2 = x2[idx]\n",
    "y2 = y.cpu().numpy()\n",
    "y2 = y2[idx]\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(f\"Input - {x2.shape}\")\n",
    "plt.imshow(x2)\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(f\"Target - {y2.shape}\")\n",
    "plt.imshow(y2)\n",
    "\n",
    "batch_idx, (x, y) = next(enumerate(val_loader))\n",
    "idx=0\n",
    "x2 = x.cpu().numpy()\n",
    "x2 = x2[idx]\n",
    "y2 = y.cpu().numpy()\n",
    "y2 = y2[idx]\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(f\"Input - {x2.shape}\")\n",
    "plt.imshow(x2)\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(f\"Target - {y2.shape}\")\n",
    "plt.imshow(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train ###\n",
    "\n",
    "if upsamp>1 and not upsamp_beforeNN:\n",
    "    initial_upsamp = True\n",
    "else: \n",
    "    initial_upsamp = False\n",
    "\n",
    "model = LadderVAE(z_dims=z_dims,blocks_per_layer=blocks_per_layer,data_mean=data_mean,data_std=data_std,noiseModel=noiseModel,n_filters=n_filters,\n",
    "                  device=device,batchnorm=batchnorm,free_bits=free_bits,img_shape=img_shape,initial_upsamp=initial_upsamp).cuda()\n",
    "\n",
    "model.train() # Model set in training mode\n",
    "\n",
    "training.train_network(model=model,lr=lr,max_epochs=max_epochs,steps_per_epoch=steps_per_epoch,directory_path=save_model_basedir,\n",
    "                       train_loader=train_loader,val_loader=val_loader,virtual_batch=virtual_batch,gaussian_noise_std=gaussian_noise_std,\n",
    "                       model_name=modelName,val_loss_patience=100,beta=beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "directory_path = \"./Trained_model/\" \n",
    "trainHist=np.load(directory_path+\"model/train_loss.npy\")\n",
    "reconHist=np.load(directory_path+\"model/train_reco_loss.npy\")\n",
    "klHist=np.load(directory_path+\"model/train_kl_loss.npy\")\n",
    "valHist=np.load(directory_path+\"model/val_loss.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 3))\n",
    "plt.subplot(1,3,1)\n",
    "plt.plot(trainHist,label='training')\n",
    "plt.plot(valHist,label='validation')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(reconHist,label='training')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"reconstruction loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.plot(klHist,label='training')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"KL loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_monalisa_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
