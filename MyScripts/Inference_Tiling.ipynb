{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We import all our dependencies.\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.optimizer import Optimizer\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from models.lvae import LadderVAE\n",
    "from boilerplate import boilerplate\n",
    "import lib.utils as utils\n",
    "import training\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import zipfile\n",
    "import urllib\n",
    "from tifffile import imread, imsave\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pathlib import Path\n",
    "from pystackreg import StackReg\n",
    "from skimage.transform import warp,AffineTransform\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### ALL PARAMETERS DEFINED HERE ####\n",
    "initial_crop_size = 1200\n",
    "infer_crop_size = 100\n",
    "\n",
    "# Data paths\n",
    "data_path_signal = Path(r\"E:\\dl_monalisa\\Data\\Vim_fixed_mltplSNR_30nm\\inference\\N2V\\Vim_fixed_Avg1-3_no_clipping\")\n",
    "data_path_obs = Path(r\"E:\\dl_monalisa\\Data\\Vim_fixed_mltplSNR_30nm\\dump\\rec\\timelapses_gathered\")\n",
    "\n",
    "# Data parameters\n",
    "upsamp = 1\n",
    "DataNoiseLvl = \"all\"\n",
    "clip = -3\n",
    "registration = False\n",
    "\n",
    "# Inference parameters\n",
    "n_pred = 1 # number of images to predict\n",
    "num_samples = 10 # number of samples used to compute MMSE estimate\n",
    "tta = False\n",
    "\n",
    "# Model loading\n",
    "modelName = \"Vim_fixed_mltplSNR_30nm_Noise1234_GMM1234boostrapped_Clip-3_5Lat_6Blocks_betaKL0.02_SupervisedAVG_NoAugment_last_vae\"\n",
    "modelPath = Path(\"./Trained_model/model/\") / (modelName + \".net\")\n",
    "# modelPath = Path(\"C:/Users/guillaume.minet/Documents/GitHub/HDN_tests/Trained_model/model/\") / (modelName + \".net\")\n",
    "\n",
    "model = torch.load(modelPath)\n",
    "model.mode_pred=True\n",
    "model.eval()\n",
    "\n",
    "\n",
    "# Saving path and options\n",
    "save_idx = 1\n",
    "data_name = str(data_path_signal).split(\"\\\\\")[3]\n",
    "save_folder = Path(r\"E:\\dl_monalisa\\Data\") / data_name / r\"inference\\HDN\\denoising\\_bestResults\" / (modelName + \"_Size1200_Tiled2\") #f\"_{save_idx}\")\n",
    "\n",
    "overwrite = True\n",
    "save_samples = True\n",
    "save_mmse = True\n",
    "save_std = False\n",
    "save_var = False\n",
    "\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "else:\n",
    "    assert overwrite == True, \"Saving folder already exists. Set overwrite = True to enable overwriting inference folder\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing 20h12ROI.zip in signals because not in filters\n",
      "Removing 20h12ROI.zip in observations because not in filters\n",
      "\n",
      "Found 2 files.\n",
      "\n",
      "Signal 20h12m47s_rec_CAM.hdf5.0.reconstruction.tiff:\tObservation 20h12m47s_rec_CAM.hdf5.0.reconstruction.tiff:\t Shape: (1711, 1711)\n",
      "Stop loading file at file 0 because reached n_pred 1\n",
      "\n",
      "\n",
      "Concatenated arrays and cropped:\tSignal: (1, 1200)\tObservation: (1, 0, 1200)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "\n",
    "##### Load data ####\n",
    "\n",
    "signal = []\n",
    "observation = []\n",
    "filters = ['tif','tiff']\n",
    "\n",
    "files_signal = os.listdir(data_path_signal)\n",
    "files_obs = os.listdir(data_path_obs)\n",
    "\n",
    "for f in files_signal:\n",
    "    if f.split('.')[-1] not in filters:\n",
    "        print(f\"removing {f} in signals because not in filters\")\n",
    "        files_signal.remove(f)\n",
    "\n",
    "for f in files_obs:\n",
    "    if f.split('.')[-1] not in filters:\n",
    "        print(f\"Removing {f} in observations because not in filters\")\n",
    "        files_obs.remove(f)\n",
    "\n",
    "assert len(files_obs) == len(files_signal)\n",
    "print(f\"\\nFound {len(files_signal)} files.\\n\")\n",
    "\n",
    "if isinstance(DataNoiseLvl,list) or DataNoiseLvl == \"all\":\n",
    "    mltplNoise = True\n",
    "else:\n",
    "    mltplNoise = False\n",
    "    nNoise = 1\n",
    "\n",
    "for i in range (len(files_obs)):\n",
    "    file_signal = files_signal [i]\n",
    "    file_obs = files_obs [i]\n",
    "    im_signal = imread(data_path_signal / file_signal)[0]\n",
    "    \n",
    "    # noise level selection\n",
    "    if DataNoiseLvl == \"all\":\n",
    "        im_obs  = imread(data_path_obs / file_obs)[:5]\n",
    "    elif isinstance(DataNoiseLvl,int) or isinstance(DataNoiseLvl,list):\n",
    "        try:\n",
    "            im_obs = imread(data_path_obs / file_obs)[DataNoiseLvl]\n",
    "        except IndexError:\n",
    "            continue\n",
    "\n",
    "    if not isinstance(clip,bool):\n",
    "        im_obs[im_obs<clip] = 0\n",
    "        im_signal[im_signal<clip] = 0\n",
    "\n",
    "    if registration:\n",
    "        if DataNoiseLvl == \"all\":\n",
    "            print(\"Registration not available for all noise level yet\")\n",
    "        else:\n",
    "            tf = StackReg.TRANSLATION\n",
    "            sr = StackReg(tf)\n",
    "            tmat = sr.register(ref=im_signal,mov=im_obs)\n",
    "            tform = AffineTransform(matrix=tmat)\n",
    "            im_obs = warp(im_obs, tform,order=0)\n",
    "\n",
    "    observation.append(im_obs)\n",
    "    signal.append(im_signal)\n",
    "\n",
    "    print(f\"Signal {file_signal}:\\tObservation {file_obs}:\\t Shape: {im_obs.shape}\")\n",
    "\n",
    "    if i+1 >= n_pred:\n",
    "        print(f\"Stop loading file at file {i} because reached n_pred {n_pred}\")\n",
    "        break\n",
    "\n",
    "# Stack to numpy array\n",
    "signal = np.stack(signal)\n",
    "observation = np.stack(observation)\n",
    "\n",
    "# Adjust array dimension if necessary\n",
    "if mltplNoise:\n",
    "    nNoise = observation.shape[1]\n",
    "    nrepeat = observation.shape[1]\n",
    "    observation = np.reshape(observation,(observation.shape[0]*observation.shape[1],observation.shape[2],observation.shape[3]))    \n",
    "    signal = np.repeat(signal,nrepeat,axis=0)\n",
    "\n",
    "# initial crop\n",
    "sizey,sizex = signal.shape[-2::]\n",
    "startx = sizex//2-(initial_crop_size//2)\n",
    "starty = sizey//2-(initial_crop_size//2)        \n",
    "signal = signal[...,starty:starty+initial_crop_size,startx:startx+initial_crop_size]\n",
    "observation = observation[...,starty:starty+initial_crop_size,startx:startx+initial_crop_size]\n",
    "\n",
    "# # Normalization\n",
    "# signal = (signal - np.mean(observation))/np.std(signal) \n",
    "# observation = (observation - np.mean(observation))/np.std(signal)\n",
    "# data_mean = 26.67201805114746\n",
    "# data_std = 55.58269500732422 \n",
    "# signal = (signal - data_mean) * data_std\n",
    "# observation = (observation - data_mean) * data_std\n",
    "\n",
    "\n",
    "#optional downsampling\n",
    "if upsamp>1:\n",
    "    signal2 = []\n",
    "    observation2 = []\n",
    "    for im in observation:\n",
    "        dwnsamp=im[::upsamp,::upsamp]\n",
    "        # interp=cv2.resize(dwnsamp, None, fx=upsamp, fy=upsamp, interpolation= cv2.INTER_CUBIC)\n",
    "        observation2.append(dwnsamp)\n",
    "    observation = np.stack(observation2)\n",
    "    # for im in signal:\n",
    "    #     dwnsamp=im[::upsamp,::upsamp]\n",
    "    #     interp=cv2.resize(dwnsamp, None, fx=upsamp, fy=upsamp, interpolation= cv2.INTER_NEAREST)\n",
    "    #     signal2.append(interp)\n",
    "    # signal = np.stack(signal2)\n",
    "\n",
    "print(f\"\\n\\nConcatenated arrays and cropped:\\tSignal: {signal.shape}\\tObservation: {observation.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display examples\n",
    "\n",
    "idxs = np.random.randint(0,observation.shape[0],2)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(1,4,1)\n",
    "plt.imshow(observation[idxs[0]],cmap=\"gray\")\n",
    "plt.title(\"Noisy\")\n",
    "\n",
    "plt.subplot(1,4,2)\n",
    "plt.imshow(signal[idxs[0]],cmap=\"gray\")\n",
    "plt.title(\"Clean\")\n",
    "\n",
    "plt.subplot(1,4,3)\n",
    "plt.imshow(observation[idxs[1]],cmap=\"gray\")\n",
    "plt.title(\"Noisy\")\n",
    "\n",
    "plt.subplot(1,4,4)\n",
    "plt.imshow(signal[idxs[1]],cmap=\"gray\")\n",
    "plt.title(\"Clean\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_samples = 1\n",
    "gaussian_noise_std = None\n",
    "img_mmse_list = []\n",
    "samples_list = []\n",
    "# for i in range(observation.shape[0]):\n",
    "for i in range (n_pred):\n",
    "    for noise in range (nNoise):\n",
    "        obs = observation[i*nNoise+noise]\n",
    "        img_mmse = np.zeros([initial_crop_size,initial_crop_size],dtype='float32')\n",
    "        samples = np.zeros([num_samples,initial_crop_size,initial_crop_size])\n",
    "        for y in range(0,initial_crop_size,infer_crop_size):\n",
    "            for x in range(0,initial_crop_size,infer_crop_size):\n",
    "                try:\n",
    "                    img_mmse_crop, samples_crop = boilerplate.predict(obs[y:y+infer_crop_size,x:x+infer_crop_size],num_samples,model,gaussian_noise_std,device,tta)\n",
    "                    img_mmse[y:y+infer_crop_size,x:x+infer_crop_size] = img_mmse_crop\n",
    "                    samples[:,y:y+infer_crop_size,x:x+infer_crop_size] = samples_crop\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "        img_mmse_list.append(img_mmse)\n",
    "        samples_list.append(np.stack(samples))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### saving solutions\n",
    "\n",
    "for i in range(n_pred):\n",
    "    if mltplNoise:\n",
    "        summary = [signal[i*nNoise]]\n",
    "        for noise in range(nNoise):\n",
    "            obs = cv2.resize(observation[i*nNoise+noise],None,fx=upsamp, fy=upsamp, interpolation= cv2.INTER_NEAREST)\n",
    "            summary.append(obs)\n",
    "            summary.append(img_mmse_list[i*nNoise+noise])\n",
    "            samples = samples_list[i*nNoise+noise] \n",
    "            std = np.std(samples,axis=0)\n",
    "            std_norm = std / img_mmse_list[i*nNoise+noise]\n",
    "            var = np.var(samples,axis=0)\n",
    "            var_norm = var / img_mmse_list[i*nNoise+noise]\n",
    "            if save_samples:\n",
    "                imsave(save_folder / f\"samples_{i:02d}_Noise{noise}_{i:02d}.tif\",samples)\n",
    "            if save_std:\n",
    "                imsave(save_folder / f\"std_{i:02d}_Noise{noise}_{i:02d}.tif\",std)\n",
    "                imsave(save_folder / f\"std_norm{i:02d}_Noise{noise}_{i:02d}.tif\",std_norm)\n",
    "            if save_var:\n",
    "                imsave(save_folder / f\"var_{i:02d}_Noise{noise}_{i:02d}.tif\",var)\n",
    "                imsave(save_folder / f\"var_norm{i:02d}_Noise{noise}_{i:02d}.tif\",var_norm)\n",
    "        \n",
    "        summary=np.stack(summary,axis=0)\n",
    "\n",
    "        if save_mmse:\n",
    "            if isinstance(DataNoiseLvl,list):\n",
    "                noise_level_str = ''.join(str(DataNoiseLvl).split(', '))[1:-1]\n",
    "            else:\n",
    "                noise_level_str = DataNoiseLvl\n",
    "            imsave(save_folder / f\"gt_inp_mmse{num_samples}_Noise{noise_level_str}_{i:02d}.tif\",summary,imagej=True,metadata={'axes':'TYX'})\n",
    "\n",
    "\n",
    "    else:\n",
    "        # obs = cv2.resize(observation[i],None,fx=upsamp, fy=upsamp, interpolation= cv2.INTER_NEAREST)\n",
    "        summary = np.stack([signal[i],observation[i],img_mmse_list[i]])\n",
    "        # summary = np.stack([observation[i],img_mmse_list[i]])\n",
    "        samples = samples_list[i]\n",
    "        std = np.std(samples,axis=0)\n",
    "        std_norm = std / img_mmse_list[i]\n",
    "        var = np.var(samples,axis=0)\n",
    "        var_norm = var / img_mmse_list[i]\n",
    "        if save_mmse:\n",
    "            imsave(save_folder / f\"gt_inp_mmse{num_samples}_Noise{DataNoiseLvl}_{i:02d}.tif\",summary,imagej=True,metadata={'axes':'TYX'})\n",
    "        if save_samples:\n",
    "            imsave(save_folder / f\"samples_{i:02d}_Noise{DataNoiseLvl}_.tif\",samples)\n",
    "        if save_std:\n",
    "            imsave(save_folder / f\"std_{i:02d}_Noise{DataNoiseLvl}_.tif\",std)\n",
    "            imsave(save_folder / f\"std_norm{i:02d}_Noise{DataNoiseLvl}_.tif\",std_norm)\n",
    "        if save_var:\n",
    "            imsave(save_folder / f\"var_{i:02d}_Noise{DataNoiseLvl}_.tif\",var)\n",
    "            imsave(save_folder / f\"var_norm{i:02d}_Noise{DataNoiseLvl}_.tif\",var_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# samples = samples_list[i]\n",
    "# mmse = img_mmse_list[i]\n",
    "# psnrs = []\n",
    "# range_psnr = np.max(observation[0])-np.min(observation[0])\n",
    "# for sample in samples: \n",
    "#     psnr = utils.PSNR(sample, img_mmse, range_psnr)\n",
    "#     psnrs.append(psnr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best = np.argmax(psnrs)\n",
    "# worst = np.argmin(psnrs)\n",
    "# print(best)\n",
    "# print(worst)\n",
    "# plt.figure(figsize=(20,20))\n",
    "# plt.imshow(samples[best],cmap='gray')\n",
    "# plt.show()\n",
    "# plt.figure(figsize=(20,20))\n",
    "# plt.imshow(samples[worst],cmap='gray')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_monalisa_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
